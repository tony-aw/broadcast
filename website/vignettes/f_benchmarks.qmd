---
title: "Benchmarks with Numpy+reticulate"
output:
  rmarkdown::html_vignette:
    toc: true
    number_sections: true
vignette: >
  %\VignetteIndexEntry{Benchmarks with Numpy+reticulate}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  warning = FALSE
)
```

```{r setup, eval=TRUE, echo=FALSE}
library(broadcast)
library(bench)
library(tinyplot)
```


&nbsp;

# Introduction

In this article, the speed of 'broadcast' is compared to the speed of 'Numpy' via {reticulate}.


&nbsp;

# Keeping comparisons fair

To keep the comparisons between 'broadcast' and 'Numpy'+'reticulate' fair, a number of measures have been taken:

 - conversion from Numpy to 'R' is DISABLED; this allows for comparing the speed more fairly. When conversion would be enabled, precious time would be wasted to convert from Numpy structures to comparable 'R' structures.
 - garbage collection is disabled in reticulate's Python. In 'R', only benchmarks with no garbage collection, or level 0 garbage collection, is used. I feel this keeps the comparisons relatively fair (but it's not perfect).
 - 'R' has more support for missing values than 'Numpy', which also leads to a difference in speed. But both 'R' and 'Numpy' handle missing values equally in decimal numbers ( 64bit floats in Numpy and 64bit doubles in 'R' ), through the `NaN` construct. Therefore, only operations on decimal numbers are compared.


&nbsp;

# Many Orthogonal Arrays


8 pairs of decimal number arrays are created in both 'R' and 'Numpy'. They all have a length of (approximately) 9*10^6 elements. Each pair will have a different number of dimensions, from 2 to 9 (hence 8 pairs of arrays).
I.e. a pair of 2d arrays, a pair of 3d arrays, etc.

These pairs of arrays are fully orthogonal, thus the maximum amount of broadcasting will be employed.

For each pair of array the outer sum is computed using 'broadcast' and 'Numpy'. This computation is repeated 100 times, and the median result is taken.

Thus we get the following code:

```{r eval = FALSE, echo=TRUE}
# set-up ====
library(broadcast)
library(tinycodet)
import_as(~rt, "reticulate")
np <- rt$import("numpy", convert = FALSE)
gc <- rt$import("gc", convert = FALSE)
get_times <- function(obj, j) {
  nms <- names(res$expression)
  j <- which(nms == j)
  idx <- rowSums(obj$gc[[j]][, 2:3]) == 0
  times <- obj$time[[j]][idx]
  return(times)
}
gc$disable()

# loop
median_bc <- median_np <- q1_bc <- q1_np <- q3_bc <- q3_np <- vector("numeric", 8)
counter <- 1L
target_len <- 9e6

for(i in 2:9) {
  print(i)
  n <- round(target_len^(1/i)) |> as.integer()
  len <- n^i
  cat("i = ", i, "\n")
  cat("n = ", n, "\n")
  cat("len = ", len, "\n")
  x.dims <- rep(c(n, 1L), i - 1)[1:i]
  y.dims <- rep(c(1L, n), i - 1)[1:i]
  a.dims <- rt$r_to_py(as.list(x.dims))
  b.dims <- rt$r_to_py(as.list(y.dims))
  
  npa <- np$random$random_sample(a.dims)
  npb <- np$random$random_sample(b.dims)
  a <- array(runif(100), x.dims)
  b <- array(runif(100), y.dims)
  
  res <- bench::mark(
    broadcast = bc.num(a, b, "+"),
    `numpy (NO conversion to R)` = npa + npb,
    check = FALSE,
    min_iterations = 100
  )
  bc_all <- get_times(res, "broadcast")
  np_all <- get_times(res, "numpy (NO conversion to R)")
  median_bc[counter] <- median(bc_all)
  median_np[counter] <- median(np_all)
  q1_bc[counter] <- quantile(bc_all, 0.25)
  q3_bc[counter] <- quantile(bc_all, 0.75)
  q1_np[counter] <- quantile(np_all, 0.25)
  q3_np[counter] <- quantile(np_all, 0.75)
  
  counter <- counter + 1L
}



```


Using {tinyplot}, the median, first quartile, and third quartile of the bench-marked computation times are presented in the following graph:

```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4}
load("bm_numpy_loop.RData")

library(tinyplot) |> suppressWarnings()

df1 <- data.frame(
  broadcast = median_bc, numpy = median_np, i = 2:9
)
df1 <- tidyr::pivot_longer(df1, 1:2, values_to = "median")
df2 <- data.frame(
  q1_bc, q1_np, i = 2:9
)
df2 <- tidyr::pivot_longer(df2, 1:2, values_to = "q1")
df3 <- data.frame(
  q3_bc, q3_np, i = 2:9
)
df3 <- tidyr::pivot_longer(df3, 1:2, values_to = "q3")

df <- cbind(df1, df2[, 3], df3[, 3])

module <- df$name
tinytheme("minimal")
tinyplot(
  df$i, df$median*1000, by = module, type = "l",
  main = "benchmarks",
  xlab = "number of dimensions",
  ylab = "median time (ms)"
)
tinyplot_add(
  min = df$q1*1000, ymax = df$q3*1000, by = module,
  type = type_ribbon(alpha = 0.25)
)


```


&nbsp;


# Large non-orthogonal arrays comparisons

How about arrays that are not fully orthogonal, but still require a lot of broadcasting in pari-wise computations?

Here is the benchmark:

```{r eval=FALSE, echo=TRUE}

library(broadcast)
library(tinycodet)
import_as(~rt, "reticulate")
np <- rt$import("numpy", convert = FALSE)
gc <- rt$import("gc", convert = FALSE)
gc$disable()

n <- 26L
npa <- np$random$rand(n, 1L, n, 1L, n)
npb <- np$random$rand(n, n, 1L, n, 1L)

a.dim <- c(n, rep(c(1L, n), 2))
b.dim <- c(n, rep(c(n, 1L), 2))
a <- array(rnorm(100), a.dim)
b <- array(rnorm(100), b.dim)

bm_numpy_large <- bench::mark(
  broadcast = bc.num(a, b, "+"),
  `numpy (no conversion to R)` = npa + npb,
  check = FALSE,
  min_iterations = 200,
)
summary(bm_numpy_large)
ggplot2::autoplot(bm_numpy_large)

```

```{r echo=FALSE, eval=TRUE, fig.width=8}
load("bm_numpy_large.RData")
summary(bm_numpy_large)
ggplot2::autoplot(bm_numpy_large)
```


&nbsp;

&nbsp;
