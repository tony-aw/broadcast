{"title":"Benchmarks with Numpy","markdown":{"yaml":{"title":"Benchmarks with Numpy","format":"html"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  warning = FALSE\n)\n```\n\n```{r setup, eval=TRUE, echo=FALSE}\nlibrary(broadcast)\nlibrary(fontawesome)\nlibrary(bench)\nlibrary(tinyplot)\n```\n\n\n&nbsp;\n\n\nIn the context of operations involving 2 (or more) arrays, “broadcasting” refers to recycling array dimensions without allocating additional memory, which is considerably faster and more memory-efficient than R’s regular dimensions replication mechanism.\n\nBefore the emergence of the 'broadcast' package, if `r fa(\"r-project\")` users wished to employ broadcasting, they essentially had to use broadcasting as it existed in a different programming language. For example, they might use the broadcasting as available in the 'Python' module 'Numpy' (perhaps via the 'reticulate' package). Or perhaps they might use the 'C++' library 'xtensor' via the R-package of the same name (or an extension thereof, like 'rray').\n\nWith the emergence of the 'broadcast' `r fa(\"r-project\")` package, users can now call broadcasted implementations without using external libraries, which spares the computing power needed for translating between object structures of different languages.\n\nThe \"broadcasting\" implementation in the 'broadcast' package is conceptually (though not programmatically) inspired by the broadcasting employed by the 'Numpy' module for 'Python', which might be the first implementation of broadcasting. More importantly, 'Numpy' is remarkably fast, and the 'broadcast' `r fa(\"r-project\")` package aims to be somewhat comparably fast.  \n\nThis page presents the comparisons in the speed of broadcasted operations, between 'broadcast' and 'Numpy'. The operation that is compared is a simple, element-wise, broadcasted addition, given by the code `x + y` in the 'Numpy' module for 'Python', and `bc.num(x, y, \"+\")` in the 'broadcast' `r fa(\"r-project\")` package.\n\nPlease bear in mind these are rough comparisons of speed. Since the comparisons involve 2 separate programming languages, `r fa(\"r-project\")` and 'Python', \"proper\" speed comparison is rather difficult even on a merely conceptual level.\n\n&nbsp;\n\n\n# Methodology\n\n## Difficulties in comparing `r fa(\"r-project\")` with 'Python'\n\nBenchmarking a 'Python' code snippet in 'Python' using a 'Python' module, and benchmarking an `r fa(\"r-project\")` code snippet in `r fa(\"r-project\")` using an `r fa(\"r-project\")` package, means mechanisms from different modules/packages are used for the benchmarking, and those 2 benchmarks may not (and probably won't) use the same timing mechanisms.\n\n'Python' and `r fa(\"r-project\")` are both languages that use garbage collections (GC). But GC really does mess up benchmarking. The way to circumvent this issue differs in 'Python' and `r fa(\"r-project\")`. In 'Python', GC can temporarily be disabled. `r fa(\"r-project\")` does not support this (as disabling GC is dangerous), so instead for `r fa(\"r-project\")` benchmarks with heavy GC just have to be filtered out.\n\nComparing the speed of 2 languages is inherently deceptively difficult. And due to the considerations given above, any form of benchmarks between `r fa(\"r-project\")` and 'Python' - including the ones given in this page - should be taken with a grain of salt.\n\n\n&nbsp;\n\n## The Set-Up\n\nThe operation that is bench-marked in this study is the operation `x + y` in 'Numpy' and the equivalent `bc. num(x, y, \"+\")` in 'broadcast'.  \nHere `x` and `y` are both decimal numeric arrays (type of 64 bit `double` in `r fa(\"r-project\")` and 64 bit `float` in 'Python'), and have the same number of dimensions.  \nThis operation is run for pairs of arrays with different number of dimensions, going from 2 dimensional to 7 dimensional.  \nSo we have `x + y` where both arrays are 2-dimensional (i.e. matrices), and `x + y` where both arrays are 3-dimensional, and so on until we have `x + y` where both arrays are 7-dimensional.  \n\nThe pairs of arrays are fully orthogonal (\"orthogonal\" in the sense as explained [here](/vignettes/d_broadcasting_explained.qmd)), thus the maximum amount of broadcasting will be employed.  \nGiven, for example, 4-dimensional arrays, the dimensions of `x` are `(n, 1, n, 1)` and the dimensions of `y` are `(1, n, 1, n)`.  \nThe value of `n`, so the size of each dimension, varies as follows: \n\n - For 2-dimensional arrays, `n` goes from 1250 to 9500, with step size 750.\n - For 3-dimensional arrays, `n` goes from 65 to 450, with step size 35.\n - For 4-dimensional arrays, `n` goes from 9 to 99, with step size 10.\n - For 5-dimensional arrays, `n` goes from 6 to 39, with step size 3.\n - For 6-dimensional arrays, `n` goes from 3 to 21, with step size 2.\n - For 7-dimensional arrays, `n` goes from 2 to 14, with step size 1.\n\nThese values `n` have been chosen as follows. The maximum `n` is chosen such that the broadcasted element-wise addition of `x` and `y` results in an array with approximately `9e7` elements (a little shy of 100 million elements). The minimum `n` is one-seventh of that value. And the step size is chosen such that the sequence has a length between 10 and 15\n\nFor each pair of arrays, the element-wise addition is computed using 'broadcast' and 'Numpy'. This computation is repeated 100 times. From these 100 benchmarks, the median, first quartile, and third quartiles are taken. There are some caveats here, in order to keep the comparisons between 'broadcast' and 'Numpy' fair, and these caveats are explained in the next sub-section.\n\n&nbsp;\n\n## Keeping comparisons (somewhat) fair\n\nTo keep the comparisons between 'broadcast' and 'Numpy' fair, a number of measures have been taken.\n\n\nDistributions of benchmarks tend to be heavily skewed. Therefore, the median measure (together with the quartiles) are taken. The median is also more stable than the mean in the face of outliers.\n\n\nGarbage collection is disabled in Python. In `r fa(\"r-project\")`, only benchmarks with no garbage collection, or level 0 garbage collection, are used. I feel this keeps the comparisons relatively fair (but it's not perfect).\n\n\nSince only benchmarks with no garbage collection, or level 0 garbage collection, are used for `r fa(\"r-project\")`, the benchmarks are run 200 times, and a check is performed that at least 100 benchmark measurements are kept in. If there are less than 100 benchmarks for a particular computation, the benchmarks are thrown away, and another attempt is made at benchmarking (but this never happened).\n\n\nIn relation to the previous point, note that the quantiles and the median (the median itself is simply the 50% quantile) are asymptotically independent of sample-size (unlike, for example, the variance, which is directly affected by sample size).\n\n\n`r fa(\"r-project\")` has more support for missing values than 'Numpy', which also leads to a difference in speed. But both `r fa(\"r-project\")` and 'Numpy' handle missing values equally in decimal numbers ( 64bit floats in Numpy and 64bit doubles in `r fa(\"r-project\")` ), through the `NaN` construct. Therefore, only operations on decimal numbers are compared.\n\n\nOperations like power (`^`) and division (`/`) need to handle special cases (like when the right-hand side of the operation is 0). I cannot guarantee that 'broadcast' and 'Numpy' will handle these special cases in the exact same way. The plus (`+`) operator, however, has no such special cases. Therefore, the comparisons on this page only involve summation.\n\n&nbsp;\n\n## Resources used\n\nThe 'benchmark' package was used for measuring speed in `r fa(\"r-project\")`, as this package can also be used to check and filter for garbage collector calls.\n\nIn 'Python', the `time.perf_counter()` function is used to accurately measure the time an operation takes. To ensure no time is wasted on printing the result in 'Python', the operation `a + b` is wrapped inside a function without a return statement.\n\nThe plots are created using the 'tinyplot' package, to display the median, first quartile, and third quartile, of the computation times.\n\nThe benchmarks were run on a laptop  (processor: 12th Gen Intel(R) Core(TM) i5-12500H 2.50 GHz) with 32GB of Ram and running Windows 11 (64 bit).\n\nThe code used to run the benchmarks can be found at the bottom of this page. `r fa(\"r-project\")` version 4.4.0 was used to run the `r fa(\"r-project\")` code, and 'Python' version 3.12.0 with 'Numpy' version 2.2.1 was used to run the 'Python' code\n\n\n&nbsp;\n\n# Results\n\n&nbsp;\n\n::: {.panel-tabset}\n\n```{r eval=TRUE, echo=FALSE}\nfig.cap.fun <- function(i) {\n  x.dim <- paste0(rep(c(\"n\", 1), 10)[1:i], collapse = \", \")\n  y.dim <- paste0(rep(c(1, \"n\"), 10)[1:i], collapse = \", \")\n  txt <- paste(\n    \"Benchmarks of the element-wise broadcasted addition of 2 decimal numeric arrays,\n    comparing the code `x + y` in the 'Numpy' 'Python'-module,\n    against the code `bc.num(x, y,\\\"+\\\")` in the 'broadcast' 'R'-package. <br>\",\n    \"Both arrays are\", i, \"-dimensional arrays. <br>\",\n    \"The dimensions of `x` are {\", x.dim, \"}; <br>\",\n    \"the dimensions of `y` are {\", y.dim, \"}. <br>\", \n    \"Here, `n` is shown on the x-axis. <br>\",\n    \"The y-axis shows the time (in ms) it took to execute the code.\",\n    \"The solid line gives the median time, and the shaded ribbon gives the first and third quartiles.\",\n    \"The higher a value is on the y-axis, the more time it takes to execute the code, the slower the code.\"\n  )\n  return(txt)\n}\n```\n\n\n## 2d arrays\n\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(2)}\n\nload(\"benchmarks/bm_bc_2d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_2d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_2d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_2d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n## 3d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(3)}\nload(\"benchmarks/bm_bc_3d.RData\")\nmedian_np = scan(\"benchmarks/bm_py_3d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_3d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_3d_q3.txt\")\n\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n\n## 4d arrays\n\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(4)}\nload(\"benchmarks/bm_bc_4d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_4d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_4d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_4d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n\n## 5d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(5)}\nload(\"benchmarks/bm_bc_5d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_5d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_5d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_5d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n\n\n## 6d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(6)}\nload(\"benchmarks/bm_bc_6d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_6d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_6d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_6d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n## 7d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(7)}\nload(\"benchmarks/bm_bc_7d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_7d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_7d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_7d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n&nbsp;\n\n:::\n\n&nbsp;\n\n# Conclusion & Discussion\n\nThe differences in the computation times between 'broadcast' and 'Numpy' are rather small. It seems reasonable to conclude that, in general, 'broadcast' and 'Numpy' have somewhat similar speeds.\n\n&nbsp;\n\nAs stated at the start of this page, comparing benchmarks between 'R' and 'Python' is deceptively challenging. I am open for suggestions on how to improve the speed comparisons between 'broadcast' and 'Numpy', and make them more fair.\n\n\n&nbsp;\n\n# The code\n\n::: {.panel-tabset}\n\n## R code\n\n```{r}\n#| eval: false\n#| echo: true\n\n# set-up ====\nlibrary(broadcast)\nget_times <- function(obj, j) {\n  nms <- names(res$expression)\n  j <- which(nms == j)\n  idx <- rowSums(obj$gc[[j]][, 2:3]) == 0\n  times <- obj$time[[j]][idx]\n  return(times)\n}\n\n\n# loop 2d ====\ngc()\ndimsizes <- seq(1250L, 9500L,  by = 750L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- c(n, 1L)\n  y.dims <- c(1L, n)\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_2d.RData\"\n)\n\n\n\n# loop 3d ====\ngc()\ndimsizes <- seq(65L, 450L,  by = 35L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 2)[1:3]\n  y.dims <- rep(c(1L, n), 2)[1:3]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_3d.RData\"\n)\n\n\n# loop 4d ====\ngc()\ndimsizes <- seq(9L, 99L,  by = 10L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 2)[1:4]\n  y.dims <- rep(c(1L, n), 2)[1:4]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_4d.RData\"\n)\n\n\n\n\n# loop 5d ====\ngc()\ndimsizes <- seq(6L, 39L,  by = 3L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 3)[1:5]\n  y.dims <- rep(c(1L, n), 3)[1:5]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_5d.RData\"\n)\n\n\n\n# loop 6d ====\ngc()\ndimsizes <- seq(3L, 21L,  by = 2L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 3)[1:6]\n  y.dims <- rep(c(1L, n), 3)[1:6]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_6d.RData\"\n)\n\n\n# loop 7d ====\ngc()\ndimsizes <- seq(2L, 14L,  by = 1L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 4)[1:7]\n  y.dims <- rep(c(1L, n), 4)[1:7]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_7d.RData\"\n)\ngc()\n\n\n```\n\n\n## Python code\n\n\n```{python}\n#| echo: true\n#| eval: false\n\n# set-up #\nimport numpy as np\nimport gc\nfrom time import perf_counter\ndef myfunc(a, b):\n  a + b\n\n# end set-up #\n\n\n# 2d array #\ngc.disable()\ndimsizes = np.arange(1250, 9501, 750)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1)\n  bdims = (1, n)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_2d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_2d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_2d_q3.txt\", q3_np)\n# end 2d array #\n\n\n\n# 3d array #\ngc.disable()\ndimsizes = np.arange(65, 451, 35)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n)\n  bdims = (1, n, 1)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_3d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_3d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_3d_q3.txt\", q3_np)\n# end 3d array #\n\n\n\n\n# 4d array #\ngc.disable()\ndimsizes = np.arange(9, 100, 10)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1)\n  bdims = (1, n, 1, n)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_4d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_4d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_4d_q3.txt\", q3_np)\n# end 4d array #\n\n\n# 5d array #\ngc.disable()\ndimsizes = np.arange(6, 40, 3)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1, n)\n  bdims = (1, n, 1, n, 1)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_5d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_5d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_5d_q3.txt\", q3_np)\n# end 5d array #\n\n\n\n\n# 6d array #\ngc.disable()\ndimsizes = np.arange(3, 22, 2)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1, n, 1)\n  bdims = (1, n, 1, n, 1, n)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_6d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_6d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_6d_q3.txt\", q3_np)\n# end 5d array #\n\n\n\n# 7d array #\ngc.disable()\ndimsizes = np.arange(2, 15, 1)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1, n, 1, n)\n  bdims = (1, n, 1, n, 1, n, 1)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_7d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_7d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_7d_q3.txt\", q3_np)\n# end 7d array #\n\n\n\n```\n\n:::\n\n\n&nbsp;\n","srcMarkdownNoYaml":"\n\n```{r, include = FALSE}\nknitr::opts_chunk$set(\n  collapse = TRUE,\n  comment = \"#>\",\n  warning = FALSE\n)\n```\n\n```{r setup, eval=TRUE, echo=FALSE}\nlibrary(broadcast)\nlibrary(fontawesome)\nlibrary(bench)\nlibrary(tinyplot)\n```\n\n\n&nbsp;\n\n# Introduction\n\nIn the context of operations involving 2 (or more) arrays, “broadcasting” refers to recycling array dimensions without allocating additional memory, which is considerably faster and more memory-efficient than R’s regular dimensions replication mechanism.\n\nBefore the emergence of the 'broadcast' package, if `r fa(\"r-project\")` users wished to employ broadcasting, they essentially had to use broadcasting as it existed in a different programming language. For example, they might use the broadcasting as available in the 'Python' module 'Numpy' (perhaps via the 'reticulate' package). Or perhaps they might use the 'C++' library 'xtensor' via the R-package of the same name (or an extension thereof, like 'rray').\n\nWith the emergence of the 'broadcast' `r fa(\"r-project\")` package, users can now call broadcasted implementations without using external libraries, which spares the computing power needed for translating between object structures of different languages.\n\nThe \"broadcasting\" implementation in the 'broadcast' package is conceptually (though not programmatically) inspired by the broadcasting employed by the 'Numpy' module for 'Python', which might be the first implementation of broadcasting. More importantly, 'Numpy' is remarkably fast, and the 'broadcast' `r fa(\"r-project\")` package aims to be somewhat comparably fast.  \n\nThis page presents the comparisons in the speed of broadcasted operations, between 'broadcast' and 'Numpy'. The operation that is compared is a simple, element-wise, broadcasted addition, given by the code `x + y` in the 'Numpy' module for 'Python', and `bc.num(x, y, \"+\")` in the 'broadcast' `r fa(\"r-project\")` package.\n\nPlease bear in mind these are rough comparisons of speed. Since the comparisons involve 2 separate programming languages, `r fa(\"r-project\")` and 'Python', \"proper\" speed comparison is rather difficult even on a merely conceptual level.\n\n&nbsp;\n\n\n# Methodology\n\n## Difficulties in comparing `r fa(\"r-project\")` with 'Python'\n\nBenchmarking a 'Python' code snippet in 'Python' using a 'Python' module, and benchmarking an `r fa(\"r-project\")` code snippet in `r fa(\"r-project\")` using an `r fa(\"r-project\")` package, means mechanisms from different modules/packages are used for the benchmarking, and those 2 benchmarks may not (and probably won't) use the same timing mechanisms.\n\n'Python' and `r fa(\"r-project\")` are both languages that use garbage collections (GC). But GC really does mess up benchmarking. The way to circumvent this issue differs in 'Python' and `r fa(\"r-project\")`. In 'Python', GC can temporarily be disabled. `r fa(\"r-project\")` does not support this (as disabling GC is dangerous), so instead for `r fa(\"r-project\")` benchmarks with heavy GC just have to be filtered out.\n\nComparing the speed of 2 languages is inherently deceptively difficult. And due to the considerations given above, any form of benchmarks between `r fa(\"r-project\")` and 'Python' - including the ones given in this page - should be taken with a grain of salt.\n\n\n&nbsp;\n\n## The Set-Up\n\nThe operation that is bench-marked in this study is the operation `x + y` in 'Numpy' and the equivalent `bc. num(x, y, \"+\")` in 'broadcast'.  \nHere `x` and `y` are both decimal numeric arrays (type of 64 bit `double` in `r fa(\"r-project\")` and 64 bit `float` in 'Python'), and have the same number of dimensions.  \nThis operation is run for pairs of arrays with different number of dimensions, going from 2 dimensional to 7 dimensional.  \nSo we have `x + y` where both arrays are 2-dimensional (i.e. matrices), and `x + y` where both arrays are 3-dimensional, and so on until we have `x + y` where both arrays are 7-dimensional.  \n\nThe pairs of arrays are fully orthogonal (\"orthogonal\" in the sense as explained [here](/vignettes/d_broadcasting_explained.qmd)), thus the maximum amount of broadcasting will be employed.  \nGiven, for example, 4-dimensional arrays, the dimensions of `x` are `(n, 1, n, 1)` and the dimensions of `y` are `(1, n, 1, n)`.  \nThe value of `n`, so the size of each dimension, varies as follows: \n\n - For 2-dimensional arrays, `n` goes from 1250 to 9500, with step size 750.\n - For 3-dimensional arrays, `n` goes from 65 to 450, with step size 35.\n - For 4-dimensional arrays, `n` goes from 9 to 99, with step size 10.\n - For 5-dimensional arrays, `n` goes from 6 to 39, with step size 3.\n - For 6-dimensional arrays, `n` goes from 3 to 21, with step size 2.\n - For 7-dimensional arrays, `n` goes from 2 to 14, with step size 1.\n\nThese values `n` have been chosen as follows. The maximum `n` is chosen such that the broadcasted element-wise addition of `x` and `y` results in an array with approximately `9e7` elements (a little shy of 100 million elements). The minimum `n` is one-seventh of that value. And the step size is chosen such that the sequence has a length between 10 and 15\n\nFor each pair of arrays, the element-wise addition is computed using 'broadcast' and 'Numpy'. This computation is repeated 100 times. From these 100 benchmarks, the median, first quartile, and third quartiles are taken. There are some caveats here, in order to keep the comparisons between 'broadcast' and 'Numpy' fair, and these caveats are explained in the next sub-section.\n\n&nbsp;\n\n## Keeping comparisons (somewhat) fair\n\nTo keep the comparisons between 'broadcast' and 'Numpy' fair, a number of measures have been taken.\n\n\nDistributions of benchmarks tend to be heavily skewed. Therefore, the median measure (together with the quartiles) are taken. The median is also more stable than the mean in the face of outliers.\n\n\nGarbage collection is disabled in Python. In `r fa(\"r-project\")`, only benchmarks with no garbage collection, or level 0 garbage collection, are used. I feel this keeps the comparisons relatively fair (but it's not perfect).\n\n\nSince only benchmarks with no garbage collection, or level 0 garbage collection, are used for `r fa(\"r-project\")`, the benchmarks are run 200 times, and a check is performed that at least 100 benchmark measurements are kept in. If there are less than 100 benchmarks for a particular computation, the benchmarks are thrown away, and another attempt is made at benchmarking (but this never happened).\n\n\nIn relation to the previous point, note that the quantiles and the median (the median itself is simply the 50% quantile) are asymptotically independent of sample-size (unlike, for example, the variance, which is directly affected by sample size).\n\n\n`r fa(\"r-project\")` has more support for missing values than 'Numpy', which also leads to a difference in speed. But both `r fa(\"r-project\")` and 'Numpy' handle missing values equally in decimal numbers ( 64bit floats in Numpy and 64bit doubles in `r fa(\"r-project\")` ), through the `NaN` construct. Therefore, only operations on decimal numbers are compared.\n\n\nOperations like power (`^`) and division (`/`) need to handle special cases (like when the right-hand side of the operation is 0). I cannot guarantee that 'broadcast' and 'Numpy' will handle these special cases in the exact same way. The plus (`+`) operator, however, has no such special cases. Therefore, the comparisons on this page only involve summation.\n\n&nbsp;\n\n## Resources used\n\nThe 'benchmark' package was used for measuring speed in `r fa(\"r-project\")`, as this package can also be used to check and filter for garbage collector calls.\n\nIn 'Python', the `time.perf_counter()` function is used to accurately measure the time an operation takes. To ensure no time is wasted on printing the result in 'Python', the operation `a + b` is wrapped inside a function without a return statement.\n\nThe plots are created using the 'tinyplot' package, to display the median, first quartile, and third quartile, of the computation times.\n\nThe benchmarks were run on a laptop  (processor: 12th Gen Intel(R) Core(TM) i5-12500H 2.50 GHz) with 32GB of Ram and running Windows 11 (64 bit).\n\nThe code used to run the benchmarks can be found at the bottom of this page. `r fa(\"r-project\")` version 4.4.0 was used to run the `r fa(\"r-project\")` code, and 'Python' version 3.12.0 with 'Numpy' version 2.2.1 was used to run the 'Python' code\n\n\n&nbsp;\n\n# Results\n\n&nbsp;\n\n::: {.panel-tabset}\n\n```{r eval=TRUE, echo=FALSE}\nfig.cap.fun <- function(i) {\n  x.dim <- paste0(rep(c(\"n\", 1), 10)[1:i], collapse = \", \")\n  y.dim <- paste0(rep(c(1, \"n\"), 10)[1:i], collapse = \", \")\n  txt <- paste(\n    \"Benchmarks of the element-wise broadcasted addition of 2 decimal numeric arrays,\n    comparing the code `x + y` in the 'Numpy' 'Python'-module,\n    against the code `bc.num(x, y,\\\"+\\\")` in the 'broadcast' 'R'-package. <br>\",\n    \"Both arrays are\", i, \"-dimensional arrays. <br>\",\n    \"The dimensions of `x` are {\", x.dim, \"}; <br>\",\n    \"the dimensions of `y` are {\", y.dim, \"}. <br>\", \n    \"Here, `n` is shown on the x-axis. <br>\",\n    \"The y-axis shows the time (in ms) it took to execute the code.\",\n    \"The solid line gives the median time, and the shaded ribbon gives the first and third quartiles.\",\n    \"The higher a value is on the y-axis, the more time it takes to execute the code, the slower the code.\"\n  )\n  return(txt)\n}\n```\n\n\n## 2d arrays\n\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(2)}\n\nload(\"benchmarks/bm_bc_2d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_2d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_2d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_2d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n## 3d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(3)}\nload(\"benchmarks/bm_bc_3d.RData\")\nmedian_np = scan(\"benchmarks/bm_py_3d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_3d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_3d_q3.txt\")\n\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n\n## 4d arrays\n\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(4)}\nload(\"benchmarks/bm_bc_4d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_4d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_4d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_4d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n\n## 5d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(5)}\nload(\"benchmarks/bm_bc_5d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_5d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_5d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_5d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n\n\n## 6d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(6)}\nload(\"benchmarks/bm_bc_6d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_6d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_6d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_6d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n\n&nbsp;\n\n\n## 7d arrays\n\n```{r echo=FALSE, eval=TRUE, fig.width=8, fig.height=4, fig.cap = fig.cap.fun(7)}\nload(\"benchmarks/bm_bc_7d.RData\")\n\nmedian_np = scan(\"benchmarks/bm_py_7d_median.txt\")\nq1_np = scan(\"benchmarks/bm_py_7d_q1.txt\")\nq3_np = scan(\"benchmarks/bm_py_7d_q3.txt\")\n\nlibrary(tinyplot) |> suppressWarnings()\n\ndf1 <- data.frame(\n  broadcast = median_bc, numpy = median_np, i = dimsizes\n)\ndf1 <- tidyr::pivot_longer(df1, 1:2, values_to = \"median\")\ndf2 <- data.frame(\n  q1_bc, q1_np, i = dimsizes\n)\ndf2 <- tidyr::pivot_longer(df2, 1:2, values_to = \"q1\")\ndf3 <- data.frame(\n  q3_bc, q3_np, i = dimsizes\n)\ndf3 <- tidyr::pivot_longer(df3, 1:2, values_to = \"q3\")\n\ndf <- cbind(df1, df2[, 3], df3[, 3])\n\nmodule <- df$name\ntinytheme(\"minimal\")\ntinyplot(\n  df$i, df$median, by = module, type = \"l\",\n  \n  xlab = \"size of each dimension\",\n  ylab = \"median time (ms)\",\n  ylim = range(df$q1, df$q3)\n)\ntinyplot_add(\n  ymin = df$q1, ymax = df$q3, by = module,\n  type = type_ribbon(alpha = 0.25)\n)\n\n```\n\n&nbsp;\n\n:::\n\n&nbsp;\n\n# Conclusion & Discussion\n\nThe differences in the computation times between 'broadcast' and 'Numpy' are rather small. It seems reasonable to conclude that, in general, 'broadcast' and 'Numpy' have somewhat similar speeds.\n\n&nbsp;\n\nAs stated at the start of this page, comparing benchmarks between 'R' and 'Python' is deceptively challenging. I am open for suggestions on how to improve the speed comparisons between 'broadcast' and 'Numpy', and make them more fair.\n\n\n&nbsp;\n\n# The code\n\n::: {.panel-tabset}\n\n## R code\n\n```{r}\n#| eval: false\n#| echo: true\n\n# set-up ====\nlibrary(broadcast)\nget_times <- function(obj, j) {\n  nms <- names(res$expression)\n  j <- which(nms == j)\n  idx <- rowSums(obj$gc[[j]][, 2:3]) == 0\n  times <- obj$time[[j]][idx]\n  return(times)\n}\n\n\n# loop 2d ====\ngc()\ndimsizes <- seq(1250L, 9500L,  by = 750L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- c(n, 1L)\n  y.dims <- c(1L, n)\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_2d.RData\"\n)\n\n\n\n# loop 3d ====\ngc()\ndimsizes <- seq(65L, 450L,  by = 35L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 2)[1:3]\n  y.dims <- rep(c(1L, n), 2)[1:3]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_3d.RData\"\n)\n\n\n# loop 4d ====\ngc()\ndimsizes <- seq(9L, 99L,  by = 10L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 2)[1:4]\n  y.dims <- rep(c(1L, n), 2)[1:4]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_4d.RData\"\n)\n\n\n\n\n# loop 5d ====\ngc()\ndimsizes <- seq(6L, 39L,  by = 3L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 3)[1:5]\n  y.dims <- rep(c(1L, n), 3)[1:5]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_5d.RData\"\n)\n\n\n\n# loop 6d ====\ngc()\ndimsizes <- seq(3L, 21L,  by = 2L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 3)[1:6]\n  y.dims <- rep(c(1L, n), 3)[1:6]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_6d.RData\"\n)\n\n\n# loop 7d ====\ngc()\ndimsizes <- seq(2L, 14L,  by = 1L)\nprint(dimsizes)\nniter <- length(dimsizes)\nmedian_bc <- q1_bc <- q3_bc <- vector(\"numeric\", niter)\ncounter <- 1L\n\nfor(i in seq_along(dimsizes)) {\n  print(i)\n  n <- dimsizes[i]\n  x.dims <- rep(c(n, 1L), 4)[1:7]\n  y.dims <- rep(c(1L, n), 4)[1:7]\n\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    min_iterations = 200\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  if(length(bc_all) < 100) {\n    stop(\"too few benchmarks for 'R'\")\n  }\n  \n  median_bc[counter] <- median(bc_all)\n  \n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  \n  \n  \n  counter <- counter + 1L\n}\n\n\nmedian_bc <- median_bc * 1000\nq1_bc <- q1_bc * 1000\nq3_bc <- q3_bc * 1000\n\nsave(\n  dimsizes, median_bc, q1_bc, q3_bc,\n  file = \"benchmarks/bm_bc_7d.RData\"\n)\ngc()\n\n\n```\n\n\n## Python code\n\n\n```{python}\n#| echo: true\n#| eval: false\n\n# set-up #\nimport numpy as np\nimport gc\nfrom time import perf_counter\ndef myfunc(a, b):\n  a + b\n\n# end set-up #\n\n\n# 2d array #\ngc.disable()\ndimsizes = np.arange(1250, 9501, 750)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1)\n  bdims = (1, n)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_2d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_2d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_2d_q3.txt\", q3_np)\n# end 2d array #\n\n\n\n# 3d array #\ngc.disable()\ndimsizes = np.arange(65, 451, 35)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n)\n  bdims = (1, n, 1)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_3d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_3d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_3d_q3.txt\", q3_np)\n# end 3d array #\n\n\n\n\n# 4d array #\ngc.disable()\ndimsizes = np.arange(9, 100, 10)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1)\n  bdims = (1, n, 1, n)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_4d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_4d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_4d_q3.txt\", q3_np)\n# end 4d array #\n\n\n# 5d array #\ngc.disable()\ndimsizes = np.arange(6, 40, 3)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1, n)\n  bdims = (1, n, 1, n, 1)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_5d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_5d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_5d_q3.txt\", q3_np)\n# end 5d array #\n\n\n\n\n# 6d array #\ngc.disable()\ndimsizes = np.arange(3, 22, 2)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1, n, 1)\n  bdims = (1, n, 1, n, 1, n)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_6d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_6d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_6d_q3.txt\", q3_np)\n# end 5d array #\n\n\n\n# 7d array #\ngc.disable()\ndimsizes = np.arange(2, 15, 1)\nmedian_np = np.zeros(len(dimsizes))\nq1_np = np.zeros(len(dimsizes))\nq3_np = np.zeros(len(dimsizes))\ndurations = np.zeros(100)\n\nfor i in range(0, len(dimsizes)):\n  print(i)\n  n = dimsizes[i]\n  adims = (n, 1, n, 1, n, 1, n)\n  bdims = (1, n, 1, n, 1, n, 1)\n  x = np.random.random_sample(adims)\n  y = np.random.random_sample(bdims)\n  \n  for j in range(0, len(durations)):\n    t1_start = perf_counter()\n    myfunc(x, y)\n    t1_stop = perf_counter()\n    durations[j] = (t1_stop-t1_start) * 1000\n  \n  median_np[i] = np.median(durations)\n  q1_np[i] = np.quantile(durations, 0.25)\n  q3_np[i] = np.quantile(durations, 0.75)\n\ngc.collect()\n\nnp.savetxt(\"benchmarks/bm_py_7d_median.txt\", median_np)\nnp.savetxt(\"benchmarks/bm_py_7d_q1.txt\", q1_np)\nnp.savetxt(\"benchmarks/bm_py_7d_q3.txt\", q3_np)\n# end 7d array #\n\n\n\n```\n\n:::\n\n\n&nbsp;\n"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true,"format-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"output-file":"e_benchmarks_numpy.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.3.450","fontsize":"1.2em","fontcolor":"#18161B","mainfont":"Tahoma","theme":["pandoc","../light.css"],"title":"Benchmarks with Numpy"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}