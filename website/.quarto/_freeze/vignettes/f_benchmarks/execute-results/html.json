{
  "hash": "44061a513b78cba45a92427a188e6c84",
  "result": {
    "markdown": "---\ntitle: \"Benchmarks with Numpy+reticulate\"\noutput:\n  rmarkdown::html_vignette:\n    toc: true\n    number_sections: true\nvignette: >\n  %\\VignetteIndexEntry{Benchmarks with Numpy+reticulate}\n  %\\VignetteEngine{knitr::rmarkdown}\n  %\\VignetteEncoding{UTF-8}\n---\n\n\n\n::: {.cell}\n\n:::\n\n\n\n&nbsp;\n\n# Introduction\n\nIn this article, the speed of 'broadcast' is compared to the speed of 'Numpy' via {reticulate}.\n\n\n&nbsp;\n\n# Keeping comparisons fair\n\nTo keep the comparisons between 'broadcast' and 'Numpy'+'reticulate' fair, a number of measures have been taken:\n\n - conversion from Numpy to 'R' is DISABLED; this allows for comparing the speed more fairly. When conversion would be enabled, precious time would be wasted to convert from Numpy structures to comparable 'R' structures.\n - garbage collection is disabled in reticulate's Python. In 'R', only benchmarks with no garbage collection, or level 0 garbage collection, is used. I feel this keeps the comparisons relatively fair (but it's not perfect).\n - 'R' has more support for missing values than 'Numpy', which also leads to a difference in speed. But both 'R' and 'Numpy' handle missing values equally in decimal numbers ( 64bit floats in Numpy and 64bit doubles in 'R' ), through the `NaN` construct. Therefore, only operations on decimal numbers are compared.\n\n\n&nbsp;\n\n# Many Orthogonal Arrays\n\n\n8 pairs of decimal number arrays are created in both 'R' and 'Numpy'. They all have a length of (approximately) 9*10^6 elements. Each pair will have a different number of dimensions, from 2 to 9 (hence 8 pairs of arrays).\nI.e. a pair of 2d arrays, a pair of 3d arrays, etc.\n\nThese pairs of arrays are fully orthogonal, thus the maximum amount of broadcasting will be employed.\n\nFor each pair of array the outer sum is computed using 'broadcast' and 'Numpy'. This computation is repeated 100 times, and the median result is taken.\n\nThus we get the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set-up ====\nlibrary(broadcast)\nlibrary(tinycodet)\nimport_as(~rt, \"reticulate\")\nnp <- rt$import(\"numpy\", convert = FALSE)\ngc <- rt$import(\"gc\", convert = FALSE)\nget_times <- function(obj, j) {\n  nms <- names(res$expression)\n  j <- which(nms == j)\n  idx <- rowSums(obj$gc[[j]][, 2:3]) == 0\n  times <- obj$time[[j]][idx]\n  return(times)\n}\ngc$disable()\n\n# loop\nmedian_bc <- median_np <- q1_bc <- q1_np <- q3_bc <- q3_np <- vector(\"numeric\", 8)\ncounter <- 1L\ntarget_len <- 9e6\n\nfor(i in 2:9) {\n  print(i)\n  n <- round(target_len^(1/i)) |> as.integer()\n  len <- n^i\n  cat(\"i = \", i, \"\\n\")\n  cat(\"n = \", n, \"\\n\")\n  cat(\"len = \", len, \"\\n\")\n  x.dims <- rep(c(n, 1L), i - 1)[1:i]\n  y.dims <- rep(c(1L, n), i - 1)[1:i]\n  a.dims <- rt$r_to_py(as.list(x.dims))\n  b.dims <- rt$r_to_py(as.list(y.dims))\n  \n  npa <- np$random$random_sample(a.dims)\n  npb <- np$random$random_sample(b.dims)\n  a <- array(runif(100), x.dims)\n  b <- array(runif(100), y.dims)\n  \n  res <- bench::mark(\n    broadcast = bc.num(a, b, \"+\"),\n    `numpy (NO conversion to R)` = npa + npb,\n    check = FALSE,\n    min_iterations = 100\n  )\n  bc_all <- get_times(res, \"broadcast\")\n  np_all <- get_times(res, \"numpy (NO conversion to R)\")\n  median_bc[counter] <- median(bc_all)\n  median_np[counter] <- median(np_all)\n  q1_bc[counter] <- quantile(bc_all, 0.25)\n  q3_bc[counter] <- quantile(bc_all, 0.75)\n  q1_np[counter] <- quantile(np_all, 0.25)\n  q3_np[counter] <- quantile(np_all, 0.75)\n  \n  counter <- counter + 1L\n}\n\n```\n:::\n\n\n\nUsing {tinyplot}, the median, first quartile, and third quartile of the bench-marked computation times are presented in the following graph:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](f_benchmarks_files/figure-html/unnamed-chunk-3-1.png){width=768}\n:::\n:::\n\n\n\n&nbsp;\n\n\n# Large non-orthogonal arrays comparisons\n\nHow about arrays that are not fully orthogonal, but still require a lot of broadcasting in pari-wise computations?\n\nHere is the benchmark:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n\nlibrary(broadcast)\nlibrary(tinycodet)\nimport_as(~rt, \"reticulate\")\nnp <- rt$import(\"numpy\", convert = FALSE)\ngc <- rt$import(\"gc\", convert = FALSE)\ngc$disable()\n\nn <- 26L\nnpa <- np$random$rand(n, 1L, n, 1L, n)\nnpb <- np$random$rand(n, n, 1L, n, 1L)\n\na.dim <- c(n, rep(c(1L, n), 2))\nb.dim <- c(n, rep(c(n, 1L), 2))\na <- array(rnorm(100), a.dim)\nb <- array(rnorm(100), b.dim)\n\nbm_numpy_large <- bench::mark(\n  broadcast = bc.num(a, b, \"+\"),\n  `numpy (no conversion to R)` = npa + npb,\n  check = FALSE,\n  min_iterations = 200,\n)\nsummary(bm_numpy_large)\nggplot2::autoplot(bm_numpy_large)\n\n```\n:::\n\n::: {.cell}\n\n```\n#> # A tibble: 2 Ã— 6\n#>   expression                      min   median `itr/sec` mem_alloc `gc/sec`\n#>   <bch:expr>                 <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n#> 1 broadcast                    16.6ms   17.6ms      55.4    90.6MB     27.3\n#> 2 numpy (no conversion to R)   25.4ms   30.9ms      32.4        0B      0\n```\n\n::: {.cell-output-display}\n![](f_benchmarks_files/figure-html/unnamed-chunk-5-1.png){width=768}\n:::\n:::\n\n\n\n&nbsp;\n\n&nbsp;\n",
    "supporting": [
      "f_benchmarks_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}